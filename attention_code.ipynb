{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position 0: [0. 1. 0.]\n",
      "Position 1: [0.84147098 0.54030231 0.00215443]\n",
      "Position 2: [ 0.90929743 -0.41614684  0.00430886]\n",
      "Position 3: [ 0.14112001 -0.9899925   0.00646326]\n",
      "[[0.98522025 1.74174051 0.75652026]\n",
      " [0.90965265 1.40965265 0.5       ]\n",
      " [0.99851226 1.75849334 0.75998108]\n",
      " [0.99560386 1.90407309 0.90846923]]\n",
      "Data shape: (4, 3)\n",
      "Positional Encoding shape: (4, 3)\n",
      "Weight Matrices shapes: (3, 3) (3, 3) (3, 3)\n",
      "Q, K, V shapes: (4, 3) (4, 3) (4, 3)\n",
      "Scores shape: (4, 4)\n",
      "Weights shape: (4, 4)\n"
     ]
    }
   ],
   "source": [
    "## Basic attention model\n",
    "from numpy import array\n",
    "from numpy import random\n",
    "from numpy import dot\n",
    "from scipy.special import softmax\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# encoder representations of four different words\n",
    "Action = array([1, 0, 0])\n",
    "get = array([0, 1, 0])\n",
    "result= array([1, 1, 0])\n",
    "here = array([0, 0, 1])\n",
    "words = array([Action, get, result, here])\n",
    "max_seq_len = 4\n",
    "\n",
    "# Generate positional encoding\n",
    "positional_encoding = np.zeros((max_seq_len, words.shape[1]))\n",
    "for pos in range(max_seq_len):\n",
    "    for i in range(words.shape[1]):\n",
    "        if i % 2 == 0:\n",
    "            positional_encoding[pos, i] = np.sin(pos / 10000 ** (i / words.shape[1]))\n",
    "        else:\n",
    "            positional_encoding[pos, i] = np.cos(pos / 10000 ** ((i - 1) / words.shape[1]))\n",
    "# Print the positional encoding values\n",
    "for pos in range(max_seq_len):\n",
    "    print(f\"Position {pos}: {positional_encoding[pos]}\")\n",
    "\n",
    "\n",
    "\n",
    "# generating the weight matrices\n",
    "random.seed(42)\n",
    "W_Q = random.randint(3, size=(3, 3))\n",
    "W_K = random.randint(3, size=(3, 3))\n",
    "W_V = random.randint(3, size=(3, 3))\n",
    "\n",
    "# generating the queries, keys and values\n",
    "Q = words @ W_Q\n",
    "K = words @ W_K\n",
    "V = words @ W_V\n",
    "\n",
    "# scoring the query vectors against all key vectors\n",
    "scores = Q @ K.transpose()\n",
    "\n",
    "# computing the weights by a softmax operation\n",
    "weights = softmax(scores / K.shape[1] ** 0.5, axis=1)\n",
    "\n",
    "# computing the attention by a weighted sum of the value vectors\n",
    "attention = weights @ V\n",
    "\n",
    "print(attention)\n",
    "print(\"Data shape:\", words.shape)\n",
    "print(\"Positional Encoding shape:\", positional_encoding.shape)\n",
    "print(\"Weight Matrices shapes:\", W_Q.shape, W_K.shape, W_V.shape)\n",
    "print(\"Q, K, V shapes:\", Q.shape, K.shape, V.shape)\n",
    "print(\"Scores shape:\", scores.shape)\n",
    "print(\"Weights shape:\", weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My', 'name', 'is', 'obasi', 'yetunde', 'I', 'live', 'in', 'south', 'korea']\n",
      "      0     1     2     3     4     5     6     7     8     9\n",
      "0  32.0  31.0  51.0  35.0  43.0  35.0  31.0  45.0  45.0  38.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# import librariestgfhrtyg\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import softmax\n",
    "\n",
    "# Load your data from a CSV file with a raw string for the file path\n",
    "data_set = pd.read_csv(r'C:\\Users\\IBOM-HB\\Downloads\\mdata.csv')\n",
    "\n",
    "text = \"My name is obasi yetunde I live in south korea\"\n",
    "tokens = text.split()\n",
    "print(tokens)\n",
    "\n",
    "# Create a DataFrame from the tokens\n",
    "data = pd.DataFrame([tokens])\n",
    "\n",
    "# Get unique words in the text\n",
    "unique_words = list(set(tokens))\n",
    "\n",
    "# Create a dictionary to map words to integer indices\n",
    "word_to_index = {word: i for i, word in enumerate(unique_words)}\n",
    "\n",
    "# Create an empty one-hot encoding DataFrame\n",
    "one_hot_data = pd.DataFrame(0, columns=unique_words, index=[0])\n",
    "\n",
    "# Fill in the one-hot encoding DataFrame\n",
    "for word in tokens:\n",
    "    one_hot_data.at[0, word] = 1\n",
    "\n",
    "# Define max_seq_len based on the number of columns (words) in your data\n",
    "max_seq_len = one_hot_data.shape[1]\n",
    "positional_encoding = np.zeros((max_seq_len, one_hot_data.shape[1]))\n",
    "\n",
    "# Generate positional encoding\n",
    "for pos in range(max_seq_len):\n",
    "    for i in range(one_hot_data.shape[1]):\n",
    "        if i % 2 == 0:\n",
    "            positional_encoding[pos, i] = np.sin(pos / 10000 ** (i / one_hot_data.shape[1]))\n",
    "        else:\n",
    "            positional_encoding[pos, i] = np.cos(pos / 10000 ** ((i - 1) / one_hot_data.shape[1]))\n",
    "\n",
    "# Generating the weight matrices\n",
    "np.random.seed(42)\n",
    "W_Q = np.random.randint(10, size=(one_hot_data.shape[1], one_hot_data.shape[1]))\n",
    "W_K = np.random.randint(10, size=(one_hot_data.shape[1], one_hot_data.shape[1]))\n",
    "W_V = np.random.randint(10, size=(one_hot_data.shape[1], one_hot_data.shape[1]))\n",
    "\n",
    "# Generating the queries, keys, and values\n",
    "Q = one_hot_data @ W_Q\n",
    "K = one_hot_data @ W_K\n",
    "V = one_hot_data @ W_V\n",
    "\n",
    "# Scoring the query vectors against all key vectors\n",
    "scores = Q @ K.transpose()\n",
    "\n",
    "# Computing the weights by a softmax operation\n",
    "weights = softmax(scores / K.shape[1] ** 0.5, axis=1)\n",
    "\n",
    "# Computing the attention by a weighted sum of the value vectors\n",
    "attention = weights @ V\n",
    "\n",
    "# Print the resulting attention\n",
    "print(attention)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
